# -*- coding: utf-8 -*-
"""DL_Project_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15zQqKN_cmdFN4J0GmsNJpnwCSRA664tg

# Dependencies
"""

!pip install torchsummary

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os

# plotting
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchsummary import summary

from torch.utils.data import Dataset, DataLoader
import torchvision
from torchvision import transforms
from tqdm import tqdm

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from tqdm import tqdm
# Image processing
from PIL import Image
import cv2

"""#Exploratory Data Analysis"""

df = pd.read_csv('/content/drive/MyDrive/DL_Project_1/age_gender.csv')
df.shape

df.info()

df['pixels'] = df['pixels'].apply(lambda x:  np.reshape(np.array(x.split(), dtype="float32"), (48,48)))
df.shape

df.head()

fig = px.histogram(df, x="age")
fig.update_layout(title_text='Age Histogram')
fig.show()

eth_values_to_labels = { 0: "White", 1: "Black", 2: "Asian", 3: "Indian", 4: "Hispanic" }
gender_values_to_labels = { 0: "Male", 1: "Female" }

df.ethnicity.value_counts()

fig = go.Figure([
    go.Bar(x=[eth_values_to_labels[i] for i in df.ethnicity.value_counts().index], 
           y=df.ethnicity.value_counts().values)
])
fig.update_layout(
    title_text='Count Plot Ethnicity',
    xaxis_title='Ethnicity',
    yaxis_title='Count'
)
fig.show()

df.gender.value_counts()

fig = go.Figure([
    go.Bar(x=[gender_values_to_labels[i] for i in df.gender.value_counts().index], 
           y=df.gender.value_counts().values)
])
fig.update_layout(
    title_text='Count Plot Gender',
    xaxis_title='Gender',
    yaxis_title='Count'
)
fig.show()

def plot_data(rows, cols, lower_value, upper_value):

    figure = plt.figure(figsize=(cols*3,rows*4))
    for i in range(1, cols*rows + 1):
        k = np.random.randint(lower_value,upper_value)
        figure.add_subplot(rows, cols, i) # adding sub plot

        gender = gender_values_to_labels[df.gender[k]]
        ethnicity = eth_values_to_labels[df.ethnicity[k]]
        age = df.age[k]
        
        im = df.pixels[k]
        # im = np.reshape(im, (48,48))
        plt.imshow(im, cmap='gray')
        plt.axis('off')
        plt.title(f'Gender:{gender}\nAge:{age}\nEthnicity:{ethnicity}')

    plt.tight_layout()
    plt.show()

"""#Different Faces on the basis of Age, Ethnicity and Gender"""

plot_data(rows=6, cols=7, lower_value=0, upper_value=len(df))

plot_data(rows=1, cols=7, lower_value=0, upper_value=1000)

plot_data(rows=2, cols=7, lower_value=len(df)-2000, upper_value=len(df))

plot_data(rows=2, cols=7, lower_value=(len(df)-4000)//2, upper_value=len(df)//2)

psum, psum_sq = 0, 0
# pixel count
image_size = 48
count = len(df) * image_size * image_size

# loop through images
for img in df.pixels:
    psum += np.sum(img)
    psum_sq += np.sum(img**2)

# mean, var and std
total_mean = psum / count
total_var  = (psum_sq / count) - (total_mean ** 2)
total_std  = np.sqrt(total_var)

# output
print('[Dataset]')
print(f'- mean: {total_mean}')
print(f'- std: {total_std}')
print(f'- var: {total_var}')

"""# Data Fetching"""

class get_data(Dataset):
    def __init__(self, df):
        self.df = df
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self,i):
        age = df['age'][i]
        eth = df['ethnicity'][i]
        gender = df['gender'][i]
        
        im = cv2.cvtColor(np.array(df['pixels'][i]),cv2.COLOR_GRAY2RGB)
        im = self.transform(im)
        
        age = torch.tensor(age)
        eth = torch.tensor(eth)
        gender = torch.tensor(gender)
        
        return im, float(age), float(eth), float(gender)

train, test = train_test_split(df, test_size=0.2, random_state=129) 

print(f'- Number of Datapoints in Training Set: {len(train)}')
print(f'- Number of Datapoints in Test Set: {len(test)}')

# CUDA?
use_cuda = torch.cuda.is_available()
print("CUDA Available:", use_cuda)

if use_cuda:
    BATCH_SIZE=64
else:
    BATCH_SIZE=32
    
print('BATCH_SIZE:', BATCH_SIZE)

kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}

train_loader = DataLoader(get_data(train), batch_size=BATCH_SIZE, shuffle=True, **kwargs)
test_loader = DataLoader(get_data(test), batch_size=BATCH_SIZE, shuffle=False, **kwargs)

"""#Helper Functions for Fine-Tuning the Deep Learning Models"""

def bifurcation(model_name):
  model = model_name(pretrained=True)
  param = model.state_dict()
  for i in param.keys():
    print(i)

def selective_finetuning_single_layer(model_name, layer_name):
  model = model_name(pretrained=True)
  for name, param in model.named_parameters():
    if param.requires_grad and layer_name in name:
      param.requires_grad = True
    else:
      param.requires_grad = False
  optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))
  return model.cuda(), torch.nn.CrossEntropyLoss().cuda(), optimizer

def grad_change(Loss_Function, Optimizer, Label = None, Predicted = None):
  Optimizer.zero_grad()
  loss = Loss_Function(Predicted, Label)
  loss.backward()
  Optimizer.step()
  return loss, Optimizer

def model(choice, Train_Loader, Test_Loader, Epochs, Model_Class=None, Loss_Function=None, Optimizer=None):
  outputs_train=[]
  outputs_test=[]
  if choice=='age':
    for Epoch in range(Epochs):
      running_loss_train=0
      running_loss_test=0
      correct_train=0
      correct_test=0
      for (image, age,_,_) in tqdm(Train_Loader):
        image = image.cuda()
        label = age.type(torch.LongTensor).cuda()
        out = Model_Class(image)
        loss, Optimizer = grad_change(Loss_Function = Loss_Function, Optimizer = Optimizer, Label = label, Predicted = out)
        running_loss_train += loss.item()
        predicted_train = out.data.max(1, keepdim=True)[1]
        correct_train += predicted_train.eq(label.data.view_as(predicted_train)).sum()
        outputs_train.append((Epoch, running_loss_train/len(Train_Loader.dataset), 100*correct_train/len(Train_Loader.dataset)))
      with torch.no_grad():
        for (image, age,_,_) in Test_Loader:
          image = image.cuda()
          label = age.type(torch.LongTensor).cuda()
          out = Model_Class(image)
          loss = Loss_Function(out,label)
          running_loss_test += loss.item()
          predicted_test = out.data.max(1, keepdim=True)[1]
          correct_test += predicted_test.eq(label.data.view_as(predicted_test)).sum()
          outputs_test.append((Epoch, running_loss_test/len(Test_Loader.dataset), 100*correct_test/len(Test_Loader.dataset)))
    return Model_Class, outputs_train, outputs_test
  if choice=='gender':
    for Epoch in range(Epochs):
      running_loss_train=0
      running_loss_test=0
      correct_train=0
      correct_test=0
      for (image, _,_,gen) in tqdm(Train_Loader):
        image = image.cuda()
        label = gen.type(torch.LongTensor).cuda()
        out = Model_Class(image)
        loss, Optimizer = grad_change(Loss_Function = Loss_Function, Optimizer = Optimizer, Label = label, Predicted = out)
        running_loss_train += loss.item()
        predicted_train = out.data.max(1, keepdim=True)[1]
        correct_train += predicted_train.eq(label.data.view_as(predicted_train)).sum()
        outputs_train.append((Epoch, running_loss_train/len(Train_Loader.dataset), 100*correct_train/len(Train_Loader.dataset)))
      with torch.no_grad():
        for (image, _,_,gen) in Test_Loader:
          image = image.cuda()
          label = gen.type(torch.LongTensor).cuda()
          out = Model_Class(image)
          loss = Loss_Function(out,label)
          running_loss_test += loss.item()
          predicted_test = out.data.max(1, keepdim=True)[1]
          correct_test += predicted_test.eq(label.data.view_as(predicted_test)).sum()
          outputs_test.append((Epoch, running_loss_test/len(Test_Loader.dataset), 100*correct_test/len(Test_Loader.dataset)))
    return Model_Class, outputs_train, outputs_test
  if choice=='ethnicity':
    for Epoch in range(Epochs):
      running_loss_train=0
      running_loss_test=0
      correct_train=0
      correct_test=0
      for (image, _,eth,_) in tqdm(Train_Loader):
        image = image.cuda()
        label = eth.type(torch.LongTensor).cuda()
        out = Model_Class(image)
        loss, Optimizer = grad_change(Loss_Function = Loss_Function, Optimizer = Optimizer, Label = label, Predicted = out)
        running_loss_train += loss.item()
        predicted_train = out.data.max(1, keepdim=True)[1]
        correct_train += predicted_train.eq(label.data.view_as(predicted_train)).sum()
        outputs_train.append((Epoch, running_loss_train/len(Train_Loader.dataset), 100*correct_train/len(Train_Loader.dataset)))
      with torch.no_grad():
        for (image, _,eth,_) in Test_Loader:
          image = image.cuda()
          label = eth.type(torch.LongTensor).cuda()
          out = Model_Class(image)
          loss = Loss_Function(out,label)
          running_loss_test += loss.item()
          predicted_test = out.data.max(1, keepdim=True)[1]
          correct_test += predicted_test.eq(label.data.view_as(predicted_test)).sum()
          outputs_test.append((Epoch, running_loss_test/len(Test_Loader.dataset), 100*correct_test/len(Test_Loader.dataset)))
    return Model_Class, outputs_train, outputs_test

bifurcation(torchvision.models.resnet50)

bifurcation(torchvision.models.vgg19)

bifurcation(torchvision.models.mobilenet_v2)

bifurcation(torchvision.models.alexnet)

"""#Age-Wise Classification"""

model_resnet, loss_resnet, optim_resnet = selective_finetuning_single_layer(torchvision.models.resnet50, 'fc')
model_resnet ,resnet_train ,resnet_test = model('age',train_loader,test_loader,10,model_resnet, loss_resnet, optim_resnet)

model_vgg, loss_vgg, optim_vgg = selective_finetuning_single_layer(torchvision.models.vgg19, 'classifier')
model_vgg ,vgg_train ,vgg_test = model('age',train_loader,test_loader,10,model_vgg, loss_vgg, optim_vgg)

model_mobilenet_v2, loss_mobilenet_v2, optim_mobilenet_v2 = selective_finetuning_single_layer(torchvision.models.mobilenet_v2, 'classifier')
model_mobilenet_v2 ,mobilenet_v2_train ,mobilenet_v2_test = model('age',train_loader,test_loader,10,model_mobilenet_v2, loss_mobilenet_v2, optim_mobilenet_v2)

model_alexnet, loss_alexnet, optim_alexnet = selective_finetuning_single_layer(torchvision.models.alexnet, 'classifier')
model_alexnet ,alexnet_train ,alexnet_test = model('age',train_loader,test_loader,10,model_alexnet, loss_alexnet, optim_alexnet)

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_train[i][1] for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variation in model for Age")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_test[i][1] for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variation in model for Age")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_train[i][2].cpu().numpy() for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variation in model for Age")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_test[i][2].cpu().numpy() for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variation in model for Age")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

"""#Ethnicity-Wise Classification"""

model_resnet, loss_resnet, optim_resnet = selective_finetuning_single_layer(torchvision.models.resnet50, 'fc')
model_resnet ,resnet_train ,resnet_test = model('ethnicity',train_loader,test_loader,10,model_resnet, loss_resnet, optim_resnet)

model_vgg, loss_vgg, optim_vgg = selective_finetuning_single_layer(torchvision.models.vgg19, 'classifier')
model_vgg ,vgg_train ,vgg_test = model('ethnicity',train_loader,test_loader,10,model_vgg, loss_vgg, optim_vgg)

model_mobilenet_v2, loss_mobilenet_v2, optim_mobilenet_v2 = selective_finetuning_single_layer(torchvision.models.mobilenet_v2, 'classifier')
model_mobilenet_v2 ,mobilenet_v2_train ,mobilenet_v2_test = model('ethnicity',train_loader,test_loader,10,model_mobilenet_v2, loss_mobilenet_v2, optim_mobilenet_v2)

model_alexnet, loss_alexnet, optim_alexnet = selective_finetuning_single_layer(torchvision.models.alexnet, 'classifier')
model_alexnet ,alexnet_train ,alexnet_test = model('ethnicity',train_loader,test_loader,10,model_alexnet, loss_alexnet, optim_alexnet)

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_train[i][1] for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variation in model for Ethnicity")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_test[i][1] for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variation in model for Ethnicity")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_train[i][2].cpu().numpy() for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variation in model for Ethnicity")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_test[i][2].cpu().numpy() for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variation in model for Ethnicity")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

"""#Gender-Wise Classification"""

model_resnet, loss_resnet, optim_resnet = selective_finetuning_single_layer(torchvision.models.resnet50, 'fc')
model_resnet ,resnet_train ,resnet_test = model('gender',train_loader,test_loader,10,model_resnet, loss_resnet, optim_resnet)

model_vgg, loss_vgg, optim_vgg = selective_finetuning_single_layer(torchvision.models.vgg19, 'classifier')
model_vgg ,vgg_train ,vgg_test = model('gender',train_loader,test_loader,10,model_vgg, loss_vgg, optim_vgg)

model_mobilenet_v2, loss_mobilenet_v2, optim_mobilenet_v2 = selective_finetuning_single_layer(torchvision.models.mobilenet_v2, 'classifier')
model_mobilenet_v2 ,mobilenet_v2_train ,mobilenet_v2_test = model('gender',train_loader,test_loader,10,model_mobilenet_v2, loss_mobilenet_v2, optim_mobilenet_v2)

model_alexnet, loss_alexnet, optim_alexnet = selective_finetuning_single_layer(torchvision.models.alexnet, 'classifier')
model_alexnet ,alexnet_train ,alexnet_test = model('gender',train_loader,test_loader,10,model_alexnet, loss_alexnet, optim_alexnet)

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_train[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_train[i][1] for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Training with variation in model for Gender")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_test[i][1] for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_test[i][1] for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Average Loss")
plt.title("Loss v/s Epochs for Testing with variation in model for Gender")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_train[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_train[i][2].cpu().numpy() for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Training with variation in model for Gender")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

plt.figure(figsize=(10,5))
plt.plot([j for j in range(1,11)],[resnet_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[vgg_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[mobilenet_v2_test[i][2].cpu().numpy() for i in range(0,10)])
plt.plot([j for j in range(1,11)],[alexnet_test[i][2].cpu().numpy() for i in range(0,10)])
plt.xlabel("Epochs")
plt.ylabel("Accuracy %")
plt.title("Accuracy v/s Epochs for Testing with variation in model for Gender")
plt.legend(["ResNet50","VGG19","MobileNet_V2","AlexNet"])
plt.show()

"""#Grad-Cams for understanding the deep insights of Fine-Tuned CNNs"""

cd drive/MyDrive/DL_Project_1/gradcam

!pip install ttach

from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image

model = torchvision.models.resnet50(pretrained=True).cuda()
target_layers = [model.layer4[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[0])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

x = cv2.cvtColor(df.pixels[0],cv2.COLOR_GRAY2RGB)*(1/255.0)

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)

plt.imshow(visualization)

model = torchvision.models.vgg19(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[0])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)

plt.imshow(visualization)

model = torchvision.models.alexnet(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[0])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)

plt.imshow(visualization)

model = torchvision.models.mobilenet_v2(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[0])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)

plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1251],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.resnet50(pretrained=True).cuda()
target_layers = [model.layer4[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1251])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1251],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.vgg19(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1251])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1251],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.alexnet(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1251])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1251],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.mobilenet_v2(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1251])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1292],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.resnet50(pretrained=True).cuda()
target_layers = [model.layer4[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1292])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1292],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.vgg19(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1292])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1292],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.alexnet(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1292])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)

x = cv2.cvtColor(df.pixels[1292],cv2.COLOR_GRAY2RGB)*(1/255.0)
model = torchvision.models.mobilenet_v2(pretrained=True).cuda()
target_layers = [model.features[-1]]
input_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize(224),
            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)
        ])(Image.fromarray(np.uint8(df.pixels[1292])).convert('RGB'))[None]

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)
grayscale_cam = cam(input_tensor=input_tensor, targets=None)

# In this example grayscale_cam has only one image in the batch:
grayscale_cam = grayscale_cam[0, :]

visualization = show_cam_on_image(cv2.resize(x,(224,224)), grayscale_cam, use_rgb=True)
plt.imshow(visualization)